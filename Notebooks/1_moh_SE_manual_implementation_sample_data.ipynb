{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3f41a6",
   "metadata": {},
   "source": [
    "## 1- Library and Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fd3ff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# for Web Scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# for text cleaning and preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ec345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_at</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>article_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الزراعة تدرس أفكارا لشركات خاصة لاستثمار مياه ...</td>\n",
       "      <td>https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%...</td>\n",
       "      <td>2021-09-01 06:55:00</td>\n",
       "      <td>2022-10-07 08:32:02.179500</td>\n",
       "      <td>كشف أمين عام وزارة الزراعة محمد الحياري لـ حسن...</td>\n",
       "      <td>[كما أكد الحياري أن التعليمات الجديدة التي ستط...</td>\n",
       "      <td>[مياه الزيبار, وزارة الزراعة, زيت الزيتون]</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الأردن والسعودية يبحثان استثناء الشاحنات الأرد...</td>\n",
       "      <td>https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%...</td>\n",
       "      <td>2021-09-02 08:55:00</td>\n",
       "      <td>2021-01-07 08:32:02.179500</td>\n",
       "      <td>يعقد اجتماع بين هيئتي النقل في الأردن والسعودي...</td>\n",
       "      <td>[وأجرى وزير النقل م.وجيه عزايزة اتصالا هاتفيا ...</td>\n",
       "      <td>[السعودية, الأردن]</td>\n",
       "      <td>News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ذكرى المولد النبوي طريق نور وهداية للبشرية</td>\n",
       "      <td>https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%...</td>\n",
       "      <td>2000-03-22 08:55:00</td>\n",
       "      <td>2002-01-07 08:32:02.179500</td>\n",
       "      <td></td>\n",
       "      <td>[يحرص المسلمون في بقاع الأرض على الاحتفال بذكر...</td>\n",
       "      <td>[ذكرى المولد النبوي]</td>\n",
       "      <td>Blog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  الزراعة تدرس أفكارا لشركات خاصة لاستثمار مياه ...   \n",
       "1  الأردن والسعودية يبحثان استثناء الشاحنات الأرد...   \n",
       "2         ذكرى المولد النبوي طريق نور وهداية للبشرية   \n",
       "\n",
       "                                                 url        published_at  \\\n",
       "0  https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%... 2021-09-01 06:55:00   \n",
       "1  https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%... 2021-09-02 08:55:00   \n",
       "2  https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%... 2000-03-22 08:55:00   \n",
       "\n",
       "                  crawled_at  \\\n",
       "0 2022-10-07 08:32:02.179500   \n",
       "1 2021-01-07 08:32:02.179500   \n",
       "2 2002-01-07 08:32:02.179500   \n",
       "\n",
       "                                             summary  \\\n",
       "0  كشف أمين عام وزارة الزراعة محمد الحياري لـ حسن...   \n",
       "1  يعقد اجتماع بين هيئتي النقل في الأردن والسعودي...   \n",
       "2                                                      \n",
       "\n",
       "                                             content  \\\n",
       "0  [كما أكد الحياري أن التعليمات الجديدة التي ستط...   \n",
       "1  [وأجرى وزير النقل م.وجيه عزايزة اتصالا هاتفيا ...   \n",
       "2  [يحرص المسلمون في بقاع الأرض على الاحتفال بذكر...   \n",
       "\n",
       "                                         tags article_type  \n",
       "0  [مياه الزيبار, وزارة الزراعة, زيت الزيتون]         News  \n",
       "1                          [السعودية, الأردن]         News  \n",
       "2                        [ذكرى المولد النبوي]         Blog  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df = pd.read_json('../Data/sample_data.json')\n",
    "docs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f9280",
   "metadata": {},
   "source": [
    "## 2- Data Preparation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392400ab",
   "metadata": {},
   "source": [
    "Cleaning Functions Applied:\n",
    "- removing mentions\n",
    "- removing punctuation\n",
    "- removing Arabic diacritics (short vowels and other harakahs)\n",
    "- removing elongation\n",
    "- removing stopwords (which is available in NLTK corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3dccb",
   "metadata": {},
   "source": [
    "#### 2.1 preparing data for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00f3d572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    كما أكد الحياري أن التعليمات الجديدة التي ستطب...\n",
       "1    وأجرى وزير النقل م.وجيه عزايزة اتصالا هاتفيا ا...\n",
       "2    يحرص المسلمون في بقاع الأرض على الاحتفال بذكرى...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['text'] = docs_df['content'].apply(lambda x: \" \".join(x))\n",
    "docs_df['text'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340c31f",
   "metadata": {},
   "source": [
    "#### 2.2 data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b567140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctuation symbols\n",
    "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation\n",
    "\n",
    "# Arabic stop words with nltk\n",
    "stop_words = stopwords.words()\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Shadda\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "def clean_text(txt): \n",
    "    #remove punctuations\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    txt = txt.translate(translator)\n",
    "    \n",
    "    # remove Tashkeel\n",
    "    txt = re.sub(arabic_diacritics, '', txt)\n",
    "    \n",
    "    # remove longation\n",
    "    txt = re.sub(\"[إأآا]\", \"ا\", txt)\n",
    "    txt = re.sub(\"ى\", \"ي\", txt)\n",
    "    txt = re.sub(\"ؤ\", \"ء\", txt)\n",
    "    txt = re.sub(\"ئ\", \"ء\", txt)\n",
    "    txt = re.sub(\"ة\", \"ه\", txt)\n",
    "    txt = re.sub(\"گ\", \"ك\", txt)\n",
    "    \n",
    "    # remove stopwords\n",
    "    txt = ' '.join(word for word in txt.split() if word not in stop_words)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32cc09c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_at</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>article_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الزراعة تدرس أفكارا لشركات خاصة لاستثمار مياه ...</td>\n",
       "      <td>https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%...</td>\n",
       "      <td>2021-09-01 06:55:00</td>\n",
       "      <td>2022-10-07 08:32:02.179500</td>\n",
       "      <td>كشف أمين عام وزارة الزراعة محمد الحياري لـ حسن...</td>\n",
       "      <td>[كما أكد الحياري أن التعليمات الجديدة التي ستط...</td>\n",
       "      <td>[مياه الزيبار, وزارة الزراعة, زيت الزيتون]</td>\n",
       "      <td>News</td>\n",
       "      <td>كما أكد الحياري أن التعليمات الجديدة التي ستطب...</td>\n",
       "      <td>اكد الحياري ان التعليمات الجديده ستطبق اعتبارا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الأردن والسعودية يبحثان استثناء الشاحنات الأرد...</td>\n",
       "      <td>https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%...</td>\n",
       "      <td>2021-09-02 08:55:00</td>\n",
       "      <td>2021-01-07 08:32:02.179500</td>\n",
       "      <td>يعقد اجتماع بين هيئتي النقل في الأردن والسعودي...</td>\n",
       "      <td>[وأجرى وزير النقل م.وجيه عزايزة اتصالا هاتفيا ...</td>\n",
       "      <td>[السعودية, الأردن]</td>\n",
       "      <td>News</td>\n",
       "      <td>وأجرى وزير النقل م.وجيه عزايزة اتصالا هاتفيا ا...</td>\n",
       "      <td>واجري وزير النقل موجيه عزايزه اتصالا هاتفيا ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ذكرى المولد النبوي طريق نور وهداية للبشرية</td>\n",
       "      <td>https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%...</td>\n",
       "      <td>2000-03-22 08:55:00</td>\n",
       "      <td>2002-01-07 08:32:02.179500</td>\n",
       "      <td></td>\n",
       "      <td>[يحرص المسلمون في بقاع الأرض على الاحتفال بذكر...</td>\n",
       "      <td>[ذكرى المولد النبوي]</td>\n",
       "      <td>Blog</td>\n",
       "      <td>يحرص المسلمون في بقاع الأرض على الاحتفال بذكرى...</td>\n",
       "      <td>يحرص المسلمون بقاع الارض علي الاحتفال بذكري مو...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  الزراعة تدرس أفكارا لشركات خاصة لاستثمار مياه ...   \n",
       "1  الأردن والسعودية يبحثان استثناء الشاحنات الأرد...   \n",
       "2         ذكرى المولد النبوي طريق نور وهداية للبشرية   \n",
       "\n",
       "                                                 url        published_at  \\\n",
       "0  https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%... 2021-09-01 06:55:00   \n",
       "1  https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%... 2021-09-02 08:55:00   \n",
       "2  https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%... 2000-03-22 08:55:00   \n",
       "\n",
       "                  crawled_at  \\\n",
       "0 2022-10-07 08:32:02.179500   \n",
       "1 2021-01-07 08:32:02.179500   \n",
       "2 2002-01-07 08:32:02.179500   \n",
       "\n",
       "                                             summary  \\\n",
       "0  كشف أمين عام وزارة الزراعة محمد الحياري لـ حسن...   \n",
       "1  يعقد اجتماع بين هيئتي النقل في الأردن والسعودي...   \n",
       "2                                                      \n",
       "\n",
       "                                             content  \\\n",
       "0  [كما أكد الحياري أن التعليمات الجديدة التي ستط...   \n",
       "1  [وأجرى وزير النقل م.وجيه عزايزة اتصالا هاتفيا ...   \n",
       "2  [يحرص المسلمون في بقاع الأرض على الاحتفال بذكر...   \n",
       "\n",
       "                                         tags article_type  \\\n",
       "0  [مياه الزيبار, وزارة الزراعة, زيت الزيتون]         News   \n",
       "1                          [السعودية, الأردن]         News   \n",
       "2                        [ذكرى المولد النبوي]         Blog   \n",
       "\n",
       "                                                text  \\\n",
       "0  كما أكد الحياري أن التعليمات الجديدة التي ستطب...   \n",
       "1  وأجرى وزير النقل م.وجيه عزايزة اتصالا هاتفيا ا...   \n",
       "2  يحرص المسلمون في بقاع الأرض على الاحتفال بذكرى...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  اكد الحياري ان التعليمات الجديده ستطبق اعتبارا...  \n",
       "1  واجري وزير النقل موجيه عزايزه اتصالا هاتفيا ال...  \n",
       "2  يحرص المسلمون بقاع الارض علي الاحتفال بذكري مو...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_df['text_clean'] = docs_df['text'].apply(clean_text)\n",
    "docs_df['summary_clean'] = docs_df['summary'].apply(clean_text)\n",
    "docs_df['title_clean'] = docs_df['title'].apply(clean_text)\n",
    "# + tags\n",
    "\n",
    "display(docs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c1763",
   "metadata": {},
   "source": [
    "#### 2.3 info and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b289ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_info_text(df_col):\n",
    "    print(f\"-> Number of Documents: {docs_df.shape[0]}\")\n",
    "    print('-' * 50, end='\\n\\n')\n",
    "\n",
    "    print('-> Documents - First 150 letters')\n",
    "    print()\n",
    "    for i, document_i in enumerate(docs_df['text_clean']):\n",
    "        print(f\"Document Number {i+1}: {document_i[:150]}..\")\n",
    "        print()\n",
    "\n",
    "    print('-' * 50)\n",
    "    \n",
    "def data_preprocessing(df_col):\n",
    "    # Instantiate a TfidfVectorizer object\n",
    "    global vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    \n",
    "    # It fits the data and transform it as a vector\n",
    "    X = vectorizer.fit_transform(df_col)\n",
    "    # Convert the X as transposed matrix\n",
    "    X = X.T.toarray()\n",
    "    # Create a DataFrame and set the vocabulary as the index\n",
    "    df = pd.DataFrame(X, index=vectorizer.get_feature_names())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e729eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Number of Documents: 3\n",
      "--------------------------------------------------\n",
      "\n",
      "-> Documents - First 150 letters\n",
      "\n",
      "Document Number 1: اكد الحياري ان التعليمات الجديده ستطبق اعتبارا الموسم الحالي اشترطت لترخيص المعاصر الجديده مواصفات معينه لتخفيض كميات مياه الزيبار السامه وماده الجفت ..\n",
      "\n",
      "Document Number 2: واجري وزير النقل موجيه عزايزه اتصالا هاتفيا اليوم نظيره السعودي جاسم الصالح لحل مشكله الشاحنات الاردنيه فرضتها اللواءح التنظيميه المحدثه لدي الهيءه ال..\n",
      "\n",
      "Document Number 3: يحرص المسلمون بقاع الارض علي الاحتفال بذكري مولد النبي الامين وسيد المرسلين محمد بن عبدالله احياء لسيرته العطره والتبصر مواعظ نحتاجها الايام لنستشف ال..\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\anaconda3\\envs\\DataEngineering\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097922</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.071215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097922</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ابو</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>يسمع</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>يشربون</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>يقاتل</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>يقول</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>يوم</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2\n",
       "12      0.000000  0.000000  0.035573\n",
       "180     0.000000  0.097922  0.000000\n",
       "256     0.071215  0.000000  0.000000\n",
       "58      0.000000  0.097922  0.000000\n",
       "ابو     0.000000  0.000000  0.071147\n",
       "...          ...       ...       ...\n",
       "يسمع    0.000000  0.000000  0.035573\n",
       "يشربون  0.000000  0.000000  0.035573\n",
       "يقاتل   0.000000  0.000000  0.035573\n",
       "يقول    0.000000  0.000000  0.035573\n",
       "يوم     0.000000  0.000000  0.035573\n",
       "\n",
       "[397 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_info_text(docs_df['text_clean'])\n",
    "text_clean_enc_df = data_preprocessing(docs_df['text_clean'])\n",
    "text_clean_enc_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223a0c0",
   "metadata": {},
   "source": [
    "## 3- Calculating Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3bf9556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_articles(q, df):\n",
    "    # Convert the query become a vector\n",
    "    q = [q]\n",
    "    q_vec = vectorizer.transform(q).toarray().reshape(df.shape[0],)\n",
    "    \n",
    "    # Calculate the similarity\n",
    "    sim = {}\n",
    "    for i in range(df.shape[1]):\n",
    "        sim[i] = np.dot(df.loc[:, i].values, q_vec) / np.linalg.norm(df.loc[:, i]) * np.linalg.norm(q_vec)\n",
    "        if np.isnan(sim[i]):\n",
    "            sim[i] = 0\n",
    "\n",
    "    # Sort the values \n",
    "    sim_sorted = list(sim.items())\n",
    "    return sim_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8c0e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: مولد النبي\n",
      "Berikut artikel dengan nilai cosine similarity tertinggi: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 0.10061669772619392), (0, 0.0), (1, 0.0)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add The Query\n",
    "q1 = 'مولد النبي'\n",
    "\n",
    "# Measures\n",
    "time_measure = None\n",
    "most_freq_measure = None  \n",
    "\n",
    "start_time = time.time()\n",
    "sorted_docs_with_scores = get_similar_articles(q1, text_clean_enc_df)  # call function\n",
    "time_measure = (time.time() - start_time) * 10**3\n",
    "\n",
    "sorted_docs_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a45b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words: 397\n",
      "most frequent word is --> يوم (396 times)\n",
      "Ratio: 1.003\n"
     ]
    }
   ],
   "source": [
    "vocab_ = vectorizer.vocabulary_\n",
    "print(f\"number of unique words: {len(vocab_.keys())}\")\n",
    "most_freq_word = sorted(vocab_.items(), key=lambda x: x[1], reverse=True)[:1][0]\n",
    "print('most frequent word is --> {} ({} times)'.format(most_freq_word[0], most_freq_word[1]))\n",
    "score = len(vocab_.keys()) / most_freq_word[1]\n",
    "print('Ratio: {:.3f}'.format(score))\n",
    "\n",
    "most_freq_measure = most_freq_word[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122f227",
   "metadata": {},
   "source": [
    "## 4- getting top documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a648df54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_docs = np.array(sorted_docs_with_scores, dtype='int32')[:5, 0]\n",
    "top_5_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f90667ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time measure: 1.0008811950683594\n",
      "frequency measure: 396\n",
      "score 1.003\n"
     ]
    }
   ],
   "source": [
    "# results \n",
    "print('time measure:', time_measure)\n",
    "print('frequency measure:', most_freq_measure)\n",
    "print('score %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803db5d6",
   "metadata": {},
   "source": [
    "## 5- Organizing Search Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32957b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df['text_clean'] = docs_df['text'].apply(clean_text)\n",
    "docs_df['summary_clean'] = docs_df['summary'].apply(clean_text)\n",
    "docs_df['title_clean'] = docs_df['title'].apply(clean_text)\n",
    "# + tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d46c319e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>published_at</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>article_type</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>summary_clean</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الزراعة تدرس أفكارا لشركات خاصة لاستثمار مياه ...</td>\n",
       "      <td>https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%...</td>\n",
       "      <td>2021-09-01 06:55:00</td>\n",
       "      <td>2022-10-07 08:32:02.179500</td>\n",
       "      <td>كشف أمين عام وزارة الزراعة محمد الحياري لـ حسن...</td>\n",
       "      <td>[كما أكد الحياري أن التعليمات الجديدة التي ستط...</td>\n",
       "      <td>[مياه الزيبار, وزارة الزراعة, زيت الزيتون]</td>\n",
       "      <td>News</td>\n",
       "      <td>كما أكد الحياري أن التعليمات الجديدة التي ستطب...</td>\n",
       "      <td>اكد الحياري ان التعليمات الجديده ستطبق اعتبارا...</td>\n",
       "      <td>كشف امين عام وزاره الزراعه محمد الحياري حسني ا...</td>\n",
       "      <td>الزراعه تدرس افكارا لشركات خاصه لاستثمار مياه ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  الزراعة تدرس أفكارا لشركات خاصة لاستثمار مياه ...   \n",
       "\n",
       "                                                 url        published_at  \\\n",
       "0  https://husna.fm/%D9%85%D8%AD%D9%84%D9%8A/%D8%... 2021-09-01 06:55:00   \n",
       "\n",
       "                  crawled_at  \\\n",
       "0 2022-10-07 08:32:02.179500   \n",
       "\n",
       "                                             summary  \\\n",
       "0  كشف أمين عام وزارة الزراعة محمد الحياري لـ حسن...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [كما أكد الحياري أن التعليمات الجديدة التي ستط...   \n",
       "\n",
       "                                         tags article_type  \\\n",
       "0  [مياه الزيبار, وزارة الزراعة, زيت الزيتون]         News   \n",
       "\n",
       "                                                text  \\\n",
       "0  كما أكد الحياري أن التعليمات الجديدة التي ستطب...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  اكد الحياري ان التعليمات الجديده ستطبق اعتبارا...   \n",
       "\n",
       "                                       summary_clean  \\\n",
       "0  كشف امين عام وزاره الزراعه محمد الحياري حسني ا...   \n",
       "\n",
       "                                         title_clean  \n",
       "0  الزراعه تدرس افكارا لشركات خاصه لاستثمار مياه ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a22b829c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [مياه الزيبار, وزارة الزراعة, زيت الزيتون]\n",
       "1                            [السعودية, الأردن]\n",
       "2                          [ذكرى المولد النبوي]\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0458fb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['مياه الزيبار', 'وزارة الزراعة', 'زيت الزيتون']\n",
      "[ True False]\n",
      "[False  True]\n",
      "[False False]\n",
      "['السعودية', 'الأردن']\n",
      "[False False]\n",
      "[False False]\n",
      "['ذكرى المولد النبوي']\n",
      "[False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 2.0), (1, 0.0), (2, 0.0)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_test = 'مياه الزراعة'\n",
    "doc_ids = list(docs_df['tags'].index)\n",
    "q_list = np.array(q_test.split(' '))\n",
    "sim_score = list(np.zeros(docs_df.shape[0]))\n",
    "\n",
    "for i, tag in enumerate(docs_df['tags']):\n",
    "    print(tag)\n",
    "    for str_tag in tag:\n",
    "        q_list_map = np.vectorize(lambda x: x in str_tag)(q_list) \n",
    "        if True in q_list_map:\n",
    "            sim_score[i] += 1\n",
    "        print(q_list_map)\n",
    "        \n",
    "        \n",
    "sim_non_sorted = list(zip(doc_ids, sim_score))\n",
    "sim_sorted = sorted(sim_non_sorted, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sim_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0039a79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- FINAL -------------------------\n",
      "resulting simalarities:\n",
      "(0.0, 0.0)\n",
      "(1.0, 0.0)\n",
      "(2.0, 0.15821931459273364)\n",
      "\n",
      "search engine time taken 2.998828887939453 ms\n",
      "search engine average score 1.021043771043771 (uniqueness/frequency)\n",
      "------------------------- ----- -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\anaconda3\\envs\\DataEngineering\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DataEngineering\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\modaj\\AppData\\Local\\Temp\\ipykernel_143704\\3369844079.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sim[i] = np.dot(df.loc[:, i].values, q_vec) / np.linalg.norm(df.loc[:, i]) * np.linalg.norm(q_vec)\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DataEngineering\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "cols_weights = [0.1, 0.5, 0.15, 0.2]\n",
    "cols = ['tags', 'text_clean', 'summary_clean', 'title_clean']\n",
    "def overall(q, df):\n",
    "    # print(\"query:\", q)\n",
    "    \n",
    "    # note: potential class vars\n",
    "    overall_time = 0\n",
    "    overall_score_measure = 0\n",
    "    similarities_list = []\n",
    "    \n",
    "    # apply search over every col of interest\n",
    "    for col in cols:\n",
    "        if col != 'tags':\n",
    "            # 1 data preprocessing(each column)\n",
    "            text_clean_enc_df = data_preprocessing(docs_df[col])\n",
    "\n",
    "            # 2- count similarities (each column)\n",
    "            time_measure = None\n",
    "            most_freq_measure = None  \n",
    "            start_time = time.time()\n",
    "            sorted_docs_with_scores_content = get_similar_articles(q, text_clean_enc_df)  # call function\n",
    "            time_measure = (time.time() - start_time) * 10**3\n",
    "\n",
    "            # 3- results\n",
    "            global vectorizer\n",
    "            vocab_ = vectorizer.vocabulary_\n",
    "            # print(f\"number of unique words: {len(vocab_.keys())}\")\n",
    "            most_freq_word = sorted(vocab_.items(), key=lambda x: x[1], reverse=True)[:1][0]\n",
    "            # print('most frequent word is --> {} ({} times)'.format(most_freq_word[0], most_freq_word[1]))\n",
    "\n",
    "            score = len(vocab_.keys()) / most_freq_word[1]\n",
    "            # print('Ratio: {:.3f}'.format(score))\n",
    "            # print()\n",
    "            # print('time measure:', time_measure)\n",
    "        else:\n",
    "            time_measure = None\n",
    "            most_freq_measure = None  \n",
    "            start_time = time.time()\n",
    "            \n",
    "            doc_ids = list(docs_df['tags'].index)\n",
    "            q_list = np.array(q.split(' '))\n",
    "            sim_score = list(np.zeros(docs_df.shape[0]))\n",
    "\n",
    "            for i, tag in enumerate(docs_df['tags']):\n",
    "                # print(tag)\n",
    "                for str_tag in tag:\n",
    "                    q_list_map = np.vectorize(lambda x: x in str_tag)(q_list) \n",
    "                    if True in q_list_map:\n",
    "                        sim_score[i] += 1\n",
    "                    # print(q_list_map)\n",
    "\n",
    "            sim_non_sorted = list(zip(doc_ids, sim_score))\n",
    "            sorted_docs_with_scores_content = sim_non_sorted\n",
    "            \n",
    "            time_measure = (time.time() - start_time) * 10**3\n",
    "            score = 0\n",
    "            \n",
    "        similarities_list.append(sorted_docs_with_scores_content)\n",
    "        overall_time += time_measure\n",
    "        overall_score_measure += (score/(len(cols) - 1))\n",
    "        \n",
    "        averaged_scores_ids = np.array(resulting_simalarities)[0, :, 0]\n",
    "        averaged_scores = np.average(np.array(resulting_simalarities)[:, :, 1], axis=0, weights=cols_weights)\n",
    "        similarities_scores = list(zip(averaged_scores_ids, averaged_scores))\n",
    "        # print('--------------------')\n",
    "    \n",
    "    return similarities_scores, overall_time, overall_score_measure\n",
    "    \n",
    "    \n",
    "q1 = 'مولد النبي'\n",
    "resulting_simalarities, SE_time, SE_avg_score = overall(q1, docs_df)\n",
    "\n",
    "print(\"-\" * 25, 'FINAL', '-' * 25)\n",
    "print('resulting simalarities:')\n",
    "for rs in resulting_simalarities:\n",
    "    print(rs)\n",
    "print()\n",
    "print('search engine time taken', SE_time, 'ms')\n",
    "print('search engine average score', SE_avg_score, '(uniqueness/frequency)')\n",
    "print(\"-\" * 25, '-----', '-' * 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ef326a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 1.       ],\n",
       "       [0.       , 0.       , 0.1006167],\n",
       "       [0.       , 0.       , 0.       ],\n",
       "       [0.       , 0.       , 0.       ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.15821931])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (1.0, 0.0), (2.0, 0.15821931459273364)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST: COMPUTING AVERAGE SIMILARITY SCORES\n",
    "# averaged_scores_ids = np.array(resulting_simalarities)[0, :, 0]\n",
    "# display(averaged_scores_ids)\n",
    "\n",
    "# display(np.array(resulting_simalarities)[:, :, 1])\n",
    "\n",
    "# averaged_scores = np.average(np.array(resulting_simalarities)[:, :, 1], axis=0, weights=cols_weights)\n",
    "# display(averaged_scores)\n",
    "\n",
    "# list(zip(averaged_scores_ids, averaged_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataEngineeringKER",
   "language": "python",
   "name": "dataengineeringker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
